version: "3.9"
services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    ports:
      - "11434:11434" # Default port for Ollama
    volumes:
      - ./ollama/entrypoint.sh:/entrypoint.sh # pull model script
      - ./ollama/models:/root/.ollama/models # model cache
    entrypoint: ["/bin/sh", "./entrypoint.sh"]
    restart: always

volumes:
  ollama_data:
